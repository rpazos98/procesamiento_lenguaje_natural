{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBLpTr7plguX"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Sentiment analysis con Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W6nuajhlqZD"
   },
   "source": [
    "### Objetivo\n",
    "El objetivo es utilizar las críticas de películas para que el sistema determine si la evaluación es positiva o negativa (sentiment analysis como clasificador binario de texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCpOVzJdl8_p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDbSydDfza5u"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def curva_roc(model, X_test, y_test):\n",
    "    y_hat_prob = model.predict(X_test).ravel()\n",
    "\n",
    "    # Calcular la exactitud (accuracy)\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print(\"Accuracy:\", scores[1])\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat_prob)\n",
    "    auc_keras = auc(fpr, tpr)\n",
    "    print('auc_keras', auc_keras)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('Curva ROC test')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UPeRkrAmbF3"
   },
   "source": [
    "### Datos\n",
    "Utilizaremos como dataset críticas de películas de IMDB puntuadas deforma positiva o negativa.\\\n",
    "Referencia del dataset: [LINK](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7jLvTU3lSyL"
   },
   "outputs": [],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "!curl -L -o 'imdb_dataset.csv' 'https://drive.google.com/u/0/uc?id=1el8tS8JZhPLd2FQWPHpvG_AIyW5np3h9&export=download&confirm=t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-SV1P3dnD1J"
   },
   "outputs": [],
   "source": [
    "# Armar el dataset\n",
    "df = pd.read_csv('imdb_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-OwSePKm-FK"
   },
   "source": [
    "### 1 - Limpieza de datos\n",
    "- En los datos se observo que en la columna \"review\" hay código HTML de salto de línea.\n",
    "- Tranformar la columna snetiment a 0 y 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hc7-AmYnPC3"
   },
   "outputs": [],
   "source": [
    "# En los datos se observó código HTML de salto de línea <br />\n",
    "import re\n",
    "df_reviews = df.copy() \n",
    "df_reviews['review'] = df['review'].apply(lambda x: re.sub(\"<br />\", \"\", x))\n",
    "df_reviews['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZtvASVOn3ty"
   },
   "outputs": [],
   "source": [
    "# Observar como está distribuido el dataset respecto a la columna Rating\n",
    "# es decir, observar que tan balanceado se encuentra respecto a cada clase\n",
    "df_reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7QJ2poZn9b-"
   },
   "outputs": [],
   "source": [
    "# Observar como está distribuido el dataset\n",
    "sns.countplot(x='sentiment', data=df_reviews)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juVSYR89x_2v"
   },
   "source": [
    "Se puede observar que el dataset está perfectamente balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVJ_RVi4o1h3"
   },
   "outputs": [],
   "source": [
    "# Tomar la columna de las review y almacenarlo todo en un vector numpy de reviews\n",
    "text_sequences = df_reviews['review'].values\n",
    "text_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nT5Un_co65Q"
   },
   "outputs": [],
   "source": [
    "# Cuantas reviews (rows) hay para evaluar?\n",
    "len(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F8hqqw05WSJ"
   },
   "outputs": [],
   "source": [
    "# - Por defecto CountVectorizer elimina los signos de puntuacion y transforma\n",
    "# todas las palabras a lowercase\n",
    "# - max_features --> limita la máxima dimensión del oneHotEncoding (max vocab_size)\n",
    "# - stop_words --> quitamos aquellas palabras que para el idioma no se consideran\n",
    "# relevantes (como los artículos, pronombres, preposiciones, adverbios, etc)\n",
    "# - Referencia:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=2000, stop_words='english')\n",
    "X = vectorizer.fit_transform(text_sequences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zp5bvozW5p3o"
   },
   "outputs": [],
   "source": [
    "# Los datos de entrada (X) son un vector de oneHotEncoding del tamaño\n",
    "# del vocabulario y de la cantidad de filas\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llVM-tzQo9_F"
   },
   "outputs": [],
   "source": [
    "# Tomar la columna rating y alcemacenarla en una variable \"y\"\n",
    "# Su shape debe ser equivalente la cantidad de rows del corpus\n",
    "y = df_reviews['sentiment'].values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmz9A6n4uK4V"
   },
   "outputs": [],
   "source": [
    "# Dividir los datos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcDPlhEouQ9E"
   },
   "outputs": [],
   "source": [
    "# Determinar la dimensiones de entrada y salida\n",
    "in_shape = X_train.shape[1] # max input sentence len\n",
    "out_shape = 1 # binary classification\n",
    "print(\"in_shape\", in_shape, \", out_shape\", out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpbQHExL6OTu"
   },
   "source": [
    "### 2 - Entrenar el modelo DNN con BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUkuWBsM6cx3"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Armar un modelo de clasificacion binaria con DNN\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(in_shape,)))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=out_shape, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiHo33J8opab"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oTSAIjeo73-"
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-cjIatVpPqW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jx1tLx23pbRi"
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yr78NmybzPMP"
   },
   "outputs": [],
   "source": [
    "# Como este modelo es binario podemos calcular la curva ROC\n",
    "curva_roc(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2_73kr1DDDS"
   },
   "source": [
    "### 3 - Entrenar un modelo previamente reduciendo el vector de entrada (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HP5uN9tqpHu_"
   },
   "outputs": [],
   "source": [
    "# Un vector de 2000 columnas es demasiado grande para entrenar un modelo clásico\n",
    "# de deep learning (DNN)\n",
    "# Se utiliza PCA para reducir la dimensionalidad\n",
    "from sklearn.decomposition import PCA\n",
    "X_pca = PCA(n_components=50).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGsHjJMD639r"
   },
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcqMV9hiDQBu"
   },
   "outputs": [],
   "source": [
    "# Dividir los datos en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_pca, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Leb-GrDahe"
   },
   "outputs": [],
   "source": [
    "# Determinar la dimensiones de entrada y salida\n",
    "in_shape = X_train2.shape[1] # max input sentence len\n",
    "out_shape = 1 # binary classification\n",
    "print(\"in_shape\", in_shape, \", out_shape\", out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMVCSYClDevO"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Utilizar la misma estructura de modelo del punto anterior\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(units=128, activation='relu', input_shape=(in_shape,)))\n",
    "model2.add(Dropout(rate=0.3))\n",
    "model2.add(Dense(units=64, activation='relu'))\n",
    "model2.add(Dropout(rate=0.5))\n",
    "model2.add(Dense(units=32, activation='relu'))\n",
    "model2.add(Dropout(rate=0.5))\n",
    "model2.add(Dense(units=out_shape, activation='sigmoid'))\n",
    "\n",
    "model2.compile(optimizer=\"Adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tM1exaqQDp4U"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model2_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4PsbnyDDSdz"
   },
   "outputs": [],
   "source": [
    "hist2 = model2.fit(X_train2, y_train2, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOHxGyacDz6f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "epoch_count = range(1, len(hist2.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist2.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist2.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSMgxRyND4CP"
   },
   "outputs": [],
   "source": [
    "model2.evaluate(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEqQbY5YECTk"
   },
   "outputs": [],
   "source": [
    "# Como este modelo es binario podemos calcular la curva ROC\n",
    "curva_roc(model2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGDesEf7sNrP"
   },
   "source": [
    "### 4 - Conclusión\n",
    "El modelo con \"bag of words\" resultó ser muy fácil de armar, barato de entrenar (liviano) y obtuvo una muy buena performance.\\\n",
    "El modelo de entrada completa (oneHotEncoding) performó mejor que el dimensión reducida con PCA pero realizó mucho overfitting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
